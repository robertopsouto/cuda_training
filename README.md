## Petrobras CUDA Training
     
### **DAY 1: Fundamental CUDA Optimization**

1. **Latency Hiding**
   - Thread and Warp Scheduling
   - Launch Configuration

2. **Memory Hierarchy and Access Patterns**
   - Local Storage, Shared Memory, and Global Memory
     
3. **Understanding Bottlenecks**
   - Memory-bound vs compute-bound codes
   - Extracting Bandwidth
   -  Memory Alignment

3. **Exercise**
   
### **DAY 2: Atomics, Reductions, Warp Shuffle**
1. **Atomics and Reductions**
   - Atomic Operations
   - Classical Parallel Reduction
   - Warp Shuffle

2. **Warp Shuffle Techniques**
   - Warp-Level Reduction
   - Broadcast and Prefix Sum

3. **Cooperative Groups**
   - Introduction to Cooperative Groups
   - Cooperative Group Functions
   - C++ Atomics

4. **Exercise**
   
### **DAY 3: CUDA Concurrency**
1. **Pinned Memory**
2. **CUDA Streams**
3. **Multi-GPU Concurrency**

### **DAY 4: CUDA Performance Optimization**

A different perspective of all the delivered content, using the GTC presentation as a baseline [CUDA Performance Optimization.](https://www.nvidia.com/en-us/on-demand/session/gtc24-s62191/)

### **DAY 5: Practical advice, code diving**

## Nsight Systems & Nsight Compute

To proper open ".nsys-rep" files, please download the tool **Nsight Systems** [[link](https://developer.nvidia.com/nsight-systems/get-started)]

Similarly, use **Nsight Compute** tool to open ".ncu-rep" files [[link](https://developer.nvidia.com/tools-overview/nsight-compute/get-started)].
